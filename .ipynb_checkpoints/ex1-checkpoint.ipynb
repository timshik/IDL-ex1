{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from DatasetLoader import MyDataset,get_dataset_as_array,get_dataset_as_torch_dataset,un_normalize_image,label_names\n",
    "# from models import SimpleModel\n",
    "# import models\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#import seaborn as sn\n",
    "import pandas as pd\n",
    "#import matplotlib.patches as mpatches\n",
    "import sklearn.metrics as met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tr_batch_size = 16\n",
    "test_batch_size = 32\n",
    "\n",
    "mydata = MyDataset(path_pos, path_neg)\n",
    "mydata.shuffle()\n",
    "my_data.split_train_test()\n",
    "trainset = mydata.get_train_data()\n",
    "testset = mydata.get_test_data\n",
    "num_of_examples = len(mydata)\n",
    "classes = list(label_names().values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data to loaders\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(my_data.get_weights(), len(weights),replacement = True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = tr_batch_size , shuffle=False, sampler=sampler)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "#parameters: the model, train data,test data, loos function, optimizer, num of epochs\n",
    "def train(model,trainloader,testloader,loss,optimizer,epochs):\n",
    "    tr_losses = []\n",
    "    dev_losses = []\n",
    "    for ep in range(epochs):\n",
    "        running_loss = 0 \n",
    "        model.train()\n",
    "        \n",
    "        for batch_idx, data in enumerate(trainloader): \n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            tr_loss = loss(outputs, labels)\n",
    "            tr_loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += tr_loss.item() # sum of all batches\n",
    "\n",
    "            if batch_idx % 1000 == 0:    # printing the loss of random batch\n",
    "                    print('[%d, %5d] loss: %.3f' %\n",
    "                          (ep + 1, batch_idx + 1, tr_loss.item()))      \n",
    "       #evaluating on dev set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            running_dev_loss = 0    \n",
    "            for data in testloader:\n",
    "                peptides, labels = data\n",
    "                outputs = model(peptides)\n",
    "                dev_loss = loss(outputs, labels)\n",
    "                running_dev_loss += dev_loss\n",
    "            tr_losses.append(running_loss/len(trainloader)) #mean loss for the epoch\n",
    "            dev_losses.append(running_dev_loss/len(testloader))\n",
    "    return tr_losses,dev_losses       \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual train\n",
    "model = SimpleModel()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00035, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5, amsgrad=False)\n",
    "tr_losses,dev_losses = train(model,trainloader,testloader,loss,optimizer,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plottind the losses \n",
    "# the dev bar might be below the train bar due to the diffrent distribution of the dev set\n",
    "iteration = np.arange(0, len(tr_losses))\n",
    "plt.plot(iteration, tr_losses, 'g-',iteration,dev_losses, 'r-')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "green_patch = mpatches.Patch(color='green', label='train')\n",
    "red_patch = mpatches.Patch(color='red', label='dev')\n",
    "plt.legend(handles=[green_patch,red_patch])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "path = './model_weights.ckpt'\n",
    "model.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluates the model with f1 score and confusion matrix\n",
    "def evaluate(model,loader,train_or_test):\n",
    "    if train_or_test == 'train':\n",
    "        batch = tr_batch_size\n",
    "    else:\n",
    "        batch = test_batch_size\n",
    "    model.eval()\n",
    "    label_list = []\n",
    "    predicted_list = []\n",
    "    for data in loader:\n",
    "        peptides, labels = data\n",
    "        label_list.extend(labels.tolist())\n",
    "        outputs = model(peptides)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predicted_list.extend(predicted.tolist())\n",
    "   \n",
    "    ### f1_score\n",
    "    f1_score = met.f1_score(label_list, predicted_list, average = 'macro')*100\n",
    "    print(' f1_score of the network %s images: %d %%' % (train_or_test,\n",
    "        f1_score))\n",
    "    ### confusion matrix\n",
    "    mat = met.confusion_matrix(label_list, predicted_list, labels =[0,1,2])\n",
    "    \n",
    "    # plt.figure(figsize=(10,7))\n",
    "    sn.set(font_scale=1.4) # for label size\n",
    "    df_cm = pd.DataFrame(mat, index = [i for i in classes],\n",
    "                  columns = [i for i in classes])\n",
    "    sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 15}) # font size\n",
    "    \n",
    "    plt.show()\n",
    "    for i in range(len(classes)):\n",
    "        print('  %s accuracy of %s images: %d %%' % (classes[i],train_or_test,\n",
    "        mat[i][i]*100/(mat[i][0]+mat[i][1]+mat[i][2])))\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate(model,trainloader,'train')\n",
    "print('------------------------------------------')\n",
    "evaluate(model,testloader,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the pretrained model and evaluating it \n",
    "# pre_trained_model = SimpleModel()\n",
    "# pre_trained_model.load('./data/pre_trained.ckpt')\n",
    "# evaluate(pre_trained_model,testloader,'test')\n",
    "\n",
    "# the model is classifying everything as cars, we can see that although the overall accuracy isnt bad(88%)\n",
    "# the f1 score is very low "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### choosing the right LR : thats the way i chose the lr (chose the one that gave the best results), more about it in the report\n",
    "# model = SimpleModel()\n",
    "# loss = nn.CrossEntropyLoss()\n",
    "# for i in range(20):\n",
    "#     r = -5 * np.random.rand()\n",
    "#     alpha = 10**r\n",
    "#     model = SimpleModel()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=alpha, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5, amsgrad=False)\n",
    "#     print(alpha) \n",
    "#     tr_losses,dev_losses = train(model,trainloader,testloader,loss,optimizer,30)\n",
    "#     iteration = np.arange(0, len(tr_losses))\n",
    "#     plt.plot(iteration, tr_losses, 'g-',iteration,dev_losses, 'r-')\n",
    "#     plt.xlabel('iterations')\n",
    "#     plt.ylabel('loss')\n",
    "#     green_patch = mpatches.Patch(color='green', label='train')\n",
    "#     red_patch = mpatches.Patch(color='red', label='dev')\n",
    "#     plt.legend(handles=[green_patch,red_patch])\n",
    "#     plt.show()\n",
    "#     print('---------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
